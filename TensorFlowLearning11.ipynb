{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowLearning11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HUSTneeb/GoogleColabCode/blob/master/TensorFlowLearning11.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "LqLnfQFtgG8w",
        "colab_type": "code",
        "outputId": "bfffd2c9-f736-4887-e6ca-acb0bd097a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.feature_column as fc\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fc5d118402be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[0;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[1;32m   5418\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5419\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5420\u001b[0;31m         server_def=None)\n\u001b[0m\u001b[1;32m   5421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[0;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[1;32m   5462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m       raise ValueError(\n\u001b[0;32m-> 5464\u001b[0;31m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[1;32m   5465\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5466\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Clzt4rjQgfcW",
        "colab_type": "code",
        "outputId": "3c557055-0e05-46bb-9f7c-a362492f07c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q requests\n",
        "!git clone --depth 1 http://github.com/tensorflow/models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "warning: redirecting to https://github.com/tensorflow/models/\n",
            "remote: Enumerating objects: 2999, done.\u001b[K\n",
            "remote: Counting objects: 100% (2999/2999), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2544/2544), done.\u001b[K\n",
            "remote: Total 2999 (delta 510), reused 1883 (delta 378), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2999/2999), 376.95 MiB | 34.98 MiB/s, done.\n",
            "Resolving deltas: 100% (510/510), done.\n",
            "Checking out files: 100% (2828/2828), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DGBDmn94gxtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_path=os.path.join(os.getcwd(),'models')\n",
        "sys.path.append(models_path)\n",
        "\n",
        "from official.wide_deep import census_dataset\n",
        "from official.wide_deep import census_main\n",
        "\n",
        "census_dataset.download(\"/tmp/census_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmSWAnN-haRi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if \"PYTHONPATH\" in os.environ:\n",
        "  os.environ['PYTHONPATH'] +=os.pathsep+models_path\n",
        "else:\n",
        "  os.environ['PYTHONPATH']=models_path\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qpS_siniJRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!python -m official.wide_deep.census_main --help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVjnKCbPiVWm",
        "colab_type": "code",
        "outputId": "08b50d36-8a7b-4b5f-d579-a5875106cdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1961
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1017 03:21:24.351117 140147817768832 tf_logging.py:115] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
            "  key: \"GPU\"\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f768c16bac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "W1017 03:21:24.352257 140147817768832 tf_logging.py:120] 'cpuinfo' not imported. CPU info will not be logged.\n",
            "I1017 03:21:29.456946 140147817768832 tf_logging.py:115] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {'gpu_info': {'count': 0}, 'memory_total': 13655257088, 'memory_available': 12793454592}, 'test_id': None, 'run_date': '2018-10-17T03:21:24.351787Z', 'tensorflow_version': {'version': '1.11.0', 'git_hash': 'unknown'}, 'tensorflow_environment_variables': [{'name': 'TF_FORCE_GPU_ALLOW_GROWTH', 'value': 'true'}], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
            "I1017 03:21:29.486066 140147817768832 tf_logging.py:115] Parsing /tmp/census_data/adult.data\n",
            "I1017 03:21:29.522732 140147817768832 tf_logging.py:115] Calling model_fn.\n",
            "I1017 03:21:30.522402 140147817768832 tf_logging.py:115] Done calling model_fn.\n",
            "I1017 03:21:30.522750 140147817768832 tf_logging.py:115] Create CheckpointSaverHook.\n",
            "I1017 03:21:30.970479 140147817768832 tf_logging.py:115] Graph was finalized.\n",
            "I1017 03:21:31.047887 140147817768832 tf_logging.py:115] Running local_init_op.\n",
            "I1017 03:21:31.067026 140147817768832 tf_logging.py:115] Done running local_init_op.\n",
            "I1017 03:21:31.737827 140147817768832 tf_logging.py:115] Saving checkpoints for 0 into /tmp/census_model/model.ckpt.\n",
            "I1017 03:21:32.428291 140147817768832 tf_logging.py:115] average_loss = 0.6931472, loss = 27.725887\n",
            "I1017 03:21:32.428570 140147817768832 tf_logging.py:115] loss = 27.725887, step = 1\n",
            "I1017 03:21:33.142235 140147817768832 tf_logging.py:115] global_step/sec: 139.994\n",
            "I1017 03:21:33.143012 140147817768832 tf_logging.py:115] average_loss = 0.49466816, loss = 19.786726 (0.715 sec)\n",
            "I1017 03:21:33.143211 140147817768832 tf_logging.py:115] loss = 19.786726, step = 101 (0.715 sec)\n",
            "I1017 03:21:33.421990 140147817768832 tf_logging.py:115] global_step/sec: 357.467\n",
            "I1017 03:21:33.422777 140147817768832 tf_logging.py:115] average_loss = 0.28736496, loss = 11.494598 (0.280 sec)\n",
            "I1017 03:21:33.423091 140147817768832 tf_logging.py:115] loss = 11.494598, step = 201 (0.280 sec)\n",
            "I1017 03:21:33.717814 140147817768832 tf_logging.py:115] global_step/sec: 338.025\n",
            "I1017 03:21:33.718679 140147817768832 tf_logging.py:115] average_loss = 0.23243165, loss = 9.297266 (0.296 sec)\n",
            "I1017 03:21:33.719029 140147817768832 tf_logging.py:115] loss = 9.297266, step = 301 (0.296 sec)\n",
            "I1017 03:21:34.003829 140147817768832 tf_logging.py:115] global_step/sec: 349.608\n",
            "I1017 03:21:34.004599 140147817768832 tf_logging.py:115] average_loss = 0.5478041, loss = 21.912165 (0.286 sec)\n",
            "I1017 03:21:34.004822 140147817768832 tf_logging.py:115] loss = 21.912165, step = 401 (0.286 sec)\n",
            "I1017 03:21:34.300275 140147817768832 tf_logging.py:115] global_step/sec: 337.331\n",
            "I1017 03:21:34.301084 140147817768832 tf_logging.py:115] average_loss = 0.20770192, loss = 8.308077 (0.296 sec)\n",
            "I1017 03:21:34.301273 140147817768832 tf_logging.py:115] loss = 8.308077, step = 501 (0.296 sec)\n",
            "I1017 03:21:34.603665 140147817768832 tf_logging.py:115] global_step/sec: 329.6\n",
            "I1017 03:21:34.604459 140147817768832 tf_logging.py:115] average_loss = 0.37259826, loss = 14.903931 (0.303 sec)\n",
            "I1017 03:21:34.604642 140147817768832 tf_logging.py:115] loss = 14.903931, step = 601 (0.303 sec)\n",
            "I1017 03:21:34.902137 140147817768832 tf_logging.py:115] global_step/sec: 335.048\n",
            "I1017 03:21:34.902936 140147817768832 tf_logging.py:115] average_loss = 0.37267327, loss = 14.906931 (0.298 sec)\n",
            "I1017 03:21:34.903129 140147817768832 tf_logging.py:115] loss = 14.906931, step = 701 (0.298 sec)\n",
            "I1017 03:21:35.214009 140147817768832 tf_logging.py:115] global_step/sec: 320.668\n",
            "I1017 03:21:35.214788 140147817768832 tf_logging.py:115] average_loss = 0.3192727, loss = 12.770908 (0.312 sec)\n",
            "I1017 03:21:35.215007 140147817768832 tf_logging.py:115] loss = 12.770908, step = 801 (0.312 sec)\n",
            "I1017 03:21:35.570288 140147817768832 tf_logging.py:115] global_step/sec: 280.662\n",
            "I1017 03:21:35.571022 140147817768832 tf_logging.py:115] average_loss = 0.41081303, loss = 16.432522 (0.356 sec)\n",
            "I1017 03:21:35.571234 140147817768832 tf_logging.py:115] loss = 16.432522, step = 901 (0.356 sec)\n",
            "I1017 03:21:35.844971 140147817768832 tf_logging.py:115] global_step/sec: 364.065\n",
            "I1017 03:21:35.845672 140147817768832 tf_logging.py:115] average_loss = 0.25888878, loss = 10.355551 (0.275 sec)\n",
            "I1017 03:21:35.845897 140147817768832 tf_logging.py:115] loss = 10.355551, step = 1001 (0.275 sec)\n",
            "I1017 03:21:36.119081 140147817768832 tf_logging.py:115] global_step/sec: 364.79\n",
            "I1017 03:21:36.119791 140147817768832 tf_logging.py:115] average_loss = 0.36284214, loss = 14.513685 (0.274 sec)\n",
            "I1017 03:21:36.120102 140147817768832 tf_logging.py:115] loss = 14.513685, step = 1101 (0.274 sec)\n",
            "I1017 03:21:36.414994 140147817768832 tf_logging.py:115] global_step/sec: 337.991\n",
            "I1017 03:21:36.415701 140147817768832 tf_logging.py:115] average_loss = 0.26606047, loss = 10.642419 (0.296 sec)\n",
            "I1017 03:21:36.415910 140147817768832 tf_logging.py:115] loss = 10.642419, step = 1201 (0.296 sec)\n",
            "I1017 03:21:36.723440 140147817768832 tf_logging.py:115] global_step/sec: 324.175\n",
            "I1017 03:21:36.724251 140147817768832 tf_logging.py:115] average_loss = 0.30887884, loss = 12.355154 (0.309 sec)\n",
            "I1017 03:21:36.724439 140147817768832 tf_logging.py:115] loss = 12.355154, step = 1301 (0.309 sec)\n",
            "I1017 03:21:37.008439 140147817768832 tf_logging.py:115] global_step/sec: 350.892\n",
            "I1017 03:21:37.009572 140147817768832 tf_logging.py:115] average_loss = 0.4112014, loss = 16.448055 (0.285 sec)\n",
            "I1017 03:21:37.009799 140147817768832 tf_logging.py:115] loss = 16.448055, step = 1401 (0.285 sec)\n",
            "I1017 03:21:37.289498 140147817768832 tf_logging.py:115] global_step/sec: 355.78\n",
            "I1017 03:21:37.290236 140147817768832 tf_logging.py:115] average_loss = 0.20217796, loss = 8.087118 (0.281 sec)\n",
            "I1017 03:21:37.290422 140147817768832 tf_logging.py:115] loss = 8.087118, step = 1501 (0.281 sec)\n",
            "I1017 03:21:37.600002 140147817768832 tf_logging.py:115] global_step/sec: 322.082\n",
            "I1017 03:21:37.600790 140147817768832 tf_logging.py:115] average_loss = 0.45089093, loss = 18.035637 (0.311 sec)\n",
            "I1017 03:21:37.601033 140147817768832 tf_logging.py:115] loss = 18.035637, step = 1601 (0.311 sec)\n",
            "I1017 03:21:37.697738 140147817768832 tf_logging.py:115] Saving checkpoints for 1629 into /tmp/census_model/model.ckpt.\n",
            "I1017 03:21:37.884875 140147817768832 tf_logging.py:115] Loss for final step: 0.004748709.\n",
            "I1017 03:21:37.896841 140147817768832 tf_logging.py:115] Parsing /tmp/census_data/adult.test\n",
            "I1017 03:21:37.925401 140147817768832 tf_logging.py:115] Calling model_fn.\n",
            "W1017 03:21:39.104347 140147817768832 tf_logging.py:125] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "W1017 03:21:39.124538 140147817768832 tf_logging.py:125] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "I1017 03:21:39.145091 140147817768832 tf_logging.py:115] Done calling model_fn.\n",
            "I1017 03:21:39.166815 140147817768832 tf_logging.py:115] Starting evaluation at 2018-10-17-03:21:39\n",
            "I1017 03:21:39.297982 140147817768832 tf_logging.py:115] Graph was finalized.\n",
            "I1017 03:21:39.301311 140147817768832 tf_logging.py:115] Restoring parameters from /tmp/census_model/model.ckpt-1629\n",
            "I1017 03:21:39.379705 140147817768832 tf_logging.py:115] Running local_init_op.\n",
            "I1017 03:21:39.419660 140147817768832 tf_logging.py:115] Done running local_init_op.\n",
            "I1017 03:21:41.588289 140147817768832 tf_logging.py:115] Finished evaluation at 2018-10-17-03:21:41\n",
            "I1017 03:21:41.588626 140147817768832 tf_logging.py:115] Saving dict for global step 1629: accuracy = 0.8355138, accuracy_baseline = 0.76377374, auc = 0.8844658, auc_precision_recall = 0.6963378, average_loss = 0.350821, global_step = 1629, label/mean = 0.23622628, loss = 13.999305, precision = 0.6742243, prediction/mean = 0.24471118, recall = 0.5876235\n",
            "I1017 03:21:41.955717 140147817768832 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 1629: /tmp/census_model/model.ckpt-1629\n",
            "I1017 03:21:41.956442 140147817768832 tf_logging.py:115] Results at epoch 2 / 2\n",
            "I1017 03:21:41.956575 140147817768832 tf_logging.py:115] ------------------------------------------------------------\n",
            "I1017 03:21:41.956661 140147817768832 tf_logging.py:115] accuracy: 0.8355138\n",
            "I1017 03:21:41.956727 140147817768832 tf_logging.py:115] accuracy_baseline: 0.76377374\n",
            "I1017 03:21:41.956794 140147817768832 tf_logging.py:115] auc: 0.8844658\n",
            "I1017 03:21:41.956885 140147817768832 tf_logging.py:115] auc_precision_recall: 0.6963378\n",
            "I1017 03:21:41.956955 140147817768832 tf_logging.py:115] average_loss: 0.350821\n",
            "I1017 03:21:41.957028 140147817768832 tf_logging.py:115] global_step: 1629\n",
            "I1017 03:21:41.957093 140147817768832 tf_logging.py:115] label/mean: 0.23622628\n",
            "I1017 03:21:41.957157 140147817768832 tf_logging.py:115] loss: 13.999305\n",
            "I1017 03:21:41.957219 140147817768832 tf_logging.py:115] precision: 0.6742243\n",
            "I1017 03:21:41.957299 140147817768832 tf_logging.py:115] prediction/mean: 0.24471118\n",
            "I1017 03:21:41.957364 140147817768832 tf_logging.py:115] recall: 0.5876235\n",
            "I1017 03:21:41.957524 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'accuracy', 'value': 0.8355137705802917, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.957483Z', 'extras': []}\n",
            "I1017 03:21:41.957638 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.957617Z', 'extras': []}\n",
            "I1017 03:21:41.957739 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'auc', 'value': 0.8844658136367798, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.957721Z', 'extras': []}\n",
            "I1017 03:21:41.957833 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6963378190994263, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.957816Z', 'extras': []}\n",
            "I1017 03:21:41.957942 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'average_loss', 'value': 0.35082098841667175, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.957925Z', 'extras': []}\n",
            "I1017 03:21:41.958034 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.958017Z', 'extras': []}\n",
            "I1017 03:21:41.958123 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'loss', 'value': 13.99930477142334, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.958107Z', 'extras': []}\n",
            "I1017 03:21:41.958214 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'precision', 'value': 0.674224317073822, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.958197Z', 'extras': []}\n",
            "I1017 03:21:41.958322 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'prediction/mean', 'value': 0.24471117556095123, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.958305Z', 'extras': []}\n",
            "I1017 03:21:41.958413 140147817768832 tf_logging.py:115] Benchmark metric: {'name': 'recall', 'value': 0.5876234769821167, 'unit': None, 'global_step': 1629, 'timestamp': '2018-10-17T03:21:41.958397Z', 'extras': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImfDrfpnjR0L",
        "colab_type": "code",
        "outputId": "72ce12b0-32dc-4c0d-c0bc-445e81108186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "!ls /tmp/census_data/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adult.data  adult.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MDvtl53Bkc9w",
        "colab_type": "code",
        "outputId": "d1d849d6-e51f-4db6-9778-f1c05f544a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "train_file=\"/tmp/census_data/adult.data\"\n",
        "test_file='/tmp/census_data/adult.test'\n",
        "\n",
        "import pandas\n",
        "\n",
        "train_df =pandas.read_csv(train_file,header=None,names=census_dataset._CSV_COLUMNS)\n",
        "test_df=pandas.read_csv(test_file,header=None,names=census_dataset._CSV_COLUMNS)\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_bracket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass  fnlwgt  education  education_num  \\\n",
              "0   39         State-gov   77516  Bachelors             13   \n",
              "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
              "2   38           Private  215646    HS-grad              9   \n",
              "3   53           Private  234721       11th              7   \n",
              "4   28           Private  338409  Bachelors             13   \n",
              "\n",
              "       marital_status         occupation   relationship   race  gender  \\\n",
              "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
              "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
              "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
              "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
              "\n",
              "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
              "0          2174             0              40  United-States          <=50K  \n",
              "1             0             0              13  United-States          <=50K  \n",
              "2             0             0              40  United-States          <=50K  \n",
              "3             0             0              40  United-States          <=50K  \n",
              "4             0             0              40           Cuba          <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "KnyFfzkdnD5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "12761145-2be8-4cc7-dffd-ee6dc7c4124b"
      },
      "cell_type": "code",
      "source": [
        "def easy_input_function(df,label_key,num_epochs,shuffle,batch_size):\n",
        "  label=df[label_key]\n",
        "  ds=tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
        "  \n",
        "  if shuffle:\n",
        "    ds=ds.shuffle(10000)\n",
        "    \n",
        "  ds=ds.batch(batch_size).repeat(num_epochs)\n",
        "  \n",
        "  return ds\n",
        "\n",
        "ds=easy_input_function(train_df,label_key='income_bracket',num_epochs=5,shuffle=True,batch_size=10)\n",
        "\n",
        "for feature_batch,label_batch in ds.take(1):\n",
        "  print('Some featrue keys: ',list(feature_batch.keys())[:5])\n",
        "  print()\n",
        "  print('A batch of Ages:',feature_batch['age'])\n",
        "  print()\n",
        "  print('A batch of Labels:',label_batch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1cb9eb5b7672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0measy_input_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'income_bracket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Some featrue keys: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    142\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sX8GYu3sEmP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}